---
sidebar_position: 05.03
---

# High availability and fault tolerance
========================

![img](/img/1-5-3-1.png)

We've already discussed some of the ways that security professionals can ensure the continued operation of systems. Let's dig into this in a little more detail. There are two key technical concepts that improve the availability of systems. High availability, otherwise known as HA, uses multiple systems to protect against failures. HA techniques are like the ones we discussed in the previous video. Having a cluster of web servers in place that can continue to operate even if a single server fails is one example. Another is using a pair of firewalls with one designated as the backup. The core concept of high availability is having operationally redundant systems, sometimes at different sites. The geographic dispersal of placing systems in different locations protects you against damage to a facility. Fault tolerance or FT helps protect a single system from failing in the first place by making it resilient in the face of technical failures. But one quick note, load balancing is a related but different concept. Load balancing uses multiple systems in an attempt to spread the burden of providing a service across those systems, providing a scalable computing environment. While they use similar technologies, load balancing and high availability are different goals. Most implementations of clustering and similar technologies are designed to achieve both high availability and load balancing but it is possible to have one without the other. Three of the most common points of failure within a computer system are the devices' power supply, storage media and networking. Fault tolerance controls can prevent the system from failing even if one of these components fails completely. Power supplies contain moving parts and as such are common points of failure. If a power supply fails, the results can be catastrophic. For this reason, server manufacturers often build dual power supplies into their servers. When a customer installs the server, they connect both of the power supplies to a power source. This way, if one power supply fails, the other power supply can continue powering the servers uninterrupted operation. For added redundancy, data centers with two separate sources of power can connect each power supply to a different power source, and they can use uninterruptible power supplies or UPS's to provide battery power to systems in the event of a brief disruption. These power sources may also be served by a generator to provide long-term backup power. Managed power distribution units or PDUs work to manage the power within a rack of servers ensuring that the power delivered to devices is clean and conditioned. The second priority of many fault tolerance efforts is protecting against the failure of a single storage device. They achieved this through the use of a technology known as RAID, Redundant Array of Inexpensive Disks. RAID comes in many different forms, but each of them is designed to provide redundancy by having more disks than needed to meet business needs. Let's look at two RAID technologies, mirroring and striping. The most basic form of RAID, known as RAID level one, is disc mirroring. In this approach, the server contains two disks. Each disc has identical contents and when the system writes any data to one disk, it automatically makes the same change to the other disk, keeping it as a synchronized copy or mirror the primary disc. If the primary disc fails, the system can automatically switch over to the backup disc and continue operating. The second major RAID technology is disc striping with parity, also known as RAID level five. In this approach, the system contains three or more disks and writes data across all of those disks but includes additional elements known as parity blocks spread across the disks. The second major RAID technology is disc striping with parity, also known as RAID level five. In this approach, the system contains three or more disks and writes data across all of those disks but it also includes additional data elements known as parity blocks that are spread across the disks. If one of the disks fails, the system can regenerate that disks contents using the parity information. But one important thing to remember, RAID is a fault-tolerance strategy that's designed to protect against a single disk failure. It is not a backup strategy. You should still perform regular data backups to protect your organization's information in the event of a more catastrophic failure, such as the physical destruction of the entire server. Networking can also be a single point of failure. For this reason, organizations should consider implementing redundancy at different points in the network. This ranges from having multiple internet service providers entering a facility to using dual network interface cards and critical servers, similar to the way that we use multiple power supplies. Using two or more network interface cards is known as NIC teaming. Within a network, add redundancy to critical network paths as well. For example, the connection between servers and their storage is crucial to the operation of the data center. Within a network, add redundancy to critical network pads as well. For example, the connection between servers and their storage is crucial to the operation of the data center. Multipath approaches create redundancy in those network connections and ensure continuous access to storage. Finally, at a higher level, think about adding diversity to your environment, wherever possible to avoid redundant elements all falling victim, to the same flaw at the same time. Use diverse technologies from a diverse set of vendors to avoid the failure of one technology or vendor from critically impacting your environment. You should also consider diversifying your cryptography and other security controls.

![img](/img/1-5-3-2.png)